Dataset Name,Description,Field,Approximate Size,How to Obtain,URL,,
JIGSAWS,"JHU-ISI Gesture and Skill Assessment Working Set: Surgical activity dataset with kinematics, video, and annotations for suturing, knot-tying, and needle-passing tasks.",Surgical,103 trials,Register and complete form at https://cs.jhu.edu/~los/jigsaws/info.php for academic use.,https://cirl.lcsr.jhu.edu/research/hmm/datasets/jigsaws_release/,,
HANDS,"Multimodal dataset for human grasp intent inference in prosthetic hands, including images, videos, EMG, and IMU data.",Grasp/Prosthetic,"413 instances + 4,466 synthetic",Log in to IEEE DataPort with free account; no IEEE membership required.,https://ieee-dataport.org/open-access/hands-multimodal-dataset-modeling-toward-human-grasp-intent-inference-prosthetic-hands,,
NinaPro,Non-Invasive Adaptive Prosthetics databases: sEMG data for hand movements and prosthetic control across multiple datasets (DB1-DB10).,Grasp/Prosthetic,"Varies (e.g., DB1: 27 subjects, 52 movements)",Publicly available; download from https://ninapro.hevs.ch/.,https://ninapro.hevs.ch/,,
ContactPose,"Dataset of grasps with object contact and hand pose, including RGB-D images and poses.",Grasp,2306 unique grasps,Download from https://contactpose.cc.gatech.edu/ or Meta AI research page.,https://ai.meta.com/research/publications/contactpose-a-dataset-of-grasps-with-object-contact-and-hand-pose/,,
GRAB,"Dataset of whole-body human grasping of objects, with 3D models and interactions.",Grasp,Not specified (multiple interactions),Download from https://grab.is.tue.mpg.de/.,https://otaheri.github.io/publication/2020_grab/,,
MISTIC-SL,Johns Hopkins Minimally Invasive Surgical Training and Innovation Center - Science of Learning: Dataset for surgical skills assessment.,Surgical,Not specified,Contact JHU or access through research papers; similar to JIGSAWS.,https://cirl.lcsr.jhu.edu/ (related to JHU datasets),,
CoPESD,Multi-level surgical motion dataset for training large models in endoscopic submucosal dissection.,Surgical,"17,679 images, 32,699 annotations",Available via arXiv paper; likely GitHub or contact authors.,https://arxiv.org/abs/2410.07540,,
SurRoL,Surgical Robot Learning: Open-source simulation platform for reinforcement learning in surgical tasks.,Surgical (Simulation),Simulation-based (10 tasks),Open-source on GitHub; from associated papers.,https://github.com/YuemingJin/SurRoL (inferred from papers),,
Dataset Name,Size (Trials/Instances),Modalities,Tasks Involved,How Obtained,URL,,
JIGSAWS,103 trials,"Kinematic (76D at 30Hz), Video (stereo at 30Hz), Gestures, GRS","Suturing, Knot-Tying, Needle-Passing",Human surgeons on da Vinci system; synchronized recordings at JHU.,https://cirl.lcsr.jhu.edu/research/hmm/datasets/jigsaws_release/,,
DESK,Varies (skills from training tasks),"Kinematic, Video",Dexterous surgical skills transfer,Robotic data during surgical training; collected for skill transfer.,https://mmasudurrah.github.io/assets/pdf/DESK-IROS-2019.pdf,,
SurgPose,"120,000+ instances","Images with keypoints, skeletons",Tool pose estimation,Real surgical videos annotated for robotic tools.,https://arxiv.org/html/2502.11534v1,,
HANDdata,"~6,000 interactions","Proximity, Kinematics, Videos",Reach-to-grasp actions,First-person sensors during human object handling.,https://www.nature.com/articles/s41597-023-02313-w,,
NinaPro (DB2/DB5),"40+ subjects, 50+ movements","sEMG, Kinematics",Grasping and hand movements,Wireless electrodes during controlled gestures.,https://ninapro.hevs.ch/,,
HANDS,"413 real + 4,466 synthetic","Images/Videos, EMG, IMU",Grasp intent with 102 objects,Headband/glove sensors in sequences.,https://arxiv.org/abs/2103.04845,,
MOVMUS-UJI,"3,883 recordings","EMG, Contextual",Continuous movements,30 participants with multimodal sensors.,Inferred from recent studies.,,
Dex-Net 2.0,6.7M point clouds,Synthetic 3D models,Robust grasping,Generated via simulations for grasp metrics.,https://www.roboticsproceedings.org/rss13/p58.pdf,,
Dataset Name,Size (Trials/Instances),Modalities,Tasks Involved,How Obtained,URL,Advantages for HINC,Limitations Addressed by HINC
JIGSAWS,103 trials (augmentable to 10k+),"Kinematic (76D/30Hz), Video (stereo/30Hz), Gestures","Suturing, Knot-Tying, Needle-Passing",8 surgeons on da Vinci; lab recordings at JHU.,https://cirl.lcsr.jhu.edu/research/hmm/datasets/jigsaws_release/,Baseline for precision; augments for DRL.,Small size; HINC uses priors for scaling.
EndoVis,1M+ frames,"Video, Annotations","Instrument segmentation, workflow recognition",Surgical videos from competitions; annotated collaboratively.,https://endovis.grand-challenge.org/,Large-scale for real surgery; video fusion.,Domain shift; HINC's CNN handles variability.
BigHand2.2M,2.2M images,"Depth Maps, Kinematics","Hand pose estimation, grasping",10 subjects with motion capture in varied poses.,https://lmb.informatik.uni-freiburg.de/resources/datasets/BigHand2.2M/,High-volume for dexterity; supports SNN training.,Static poses; HINC adds dynamic RL.
NinaPro (DB2/DB5),"40+ subjects, 50+ movements (thousands total)","sEMG, Kinematics","Grasping, daily motions",Wireless electrodes in controlled gestures.,https://ninapro.hevs.ch/,Multimodal for prosthetics; real-user data.,Noise sensitivity; HINC's bio-fidelity loss mitigates.
Dex-Net 4.0,5M grasps,"Point Clouds, Metrics",Robust grasping planning,Simulated physics with 3D models.,https://arxiv.org/abs/1909.11269,Massive synthetic for success rates.,Sim-only; HINC bridges to real via priors.
HANDdata,"~6,000 interactions","Proximity, Kinematics, Videos",Reach-to-grasp,First-person sensors in object handling.,https://www.nature.com/articles/s41597-023-02313-w,Dynamic actions; augments to 10k+.,Limited subjects; HINC generalizes via DRL.
HANDS,"413 real + 4,466 synthetic","Images/Videos, EMG, IMU",Grasp intent (102 objects),Headband/glove sensors in sequences.,https://arxiv.org/abs/2103.04845,Synthetic scaling; multimodal fusion.,Intent focus; HINC extends to outcomes.
MOVMUS-UJI,"3,883 recordings","EMG, Contextual",Continuous movements,30 participants with sensors in daily tasks.,https://zenodo.org/records/10028790,Large for continuous control; real-world.,Variability; HINC's SNN for efficiency.
Dex-Net 2.0,6.7M point clouds,"Synthetic 3D, Grasp Metrics",Grasp prediction,Generated via simulations.,https://www.roboticsproceedings.org/rss13/p58.pdf,Vast for metrics like F1; baseline comparisons.,Synthetic bias; HINC refines with human data.
SurgPose,"120,000+ instances","Images, Keypoints, Skeletons",Tool pose estimation,Annotated surgical videos.,https://arxiv.org/html/2502.11534v1,High-volume for surgery; precision MSE.,Annotation cost; HINC automates via PPO.
